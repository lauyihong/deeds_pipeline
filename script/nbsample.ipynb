{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/yifeng/Documents/GitHub/deeds_pipeline\n",
      "✓ All imports successful\n",
      "✓ nest_asyncio applied for Jupyter compatibility\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Environment Setup and Imports\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Project root directory\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'script' else Path.cwd()\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Add to path\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Import refactored step modules (with function interfaces)\n",
    "from deeds_pipeline.step3_scraper import process_deeds_scraping\n",
    "from deeds_pipeline.step4_geolocation import process_deeds_geolocation\n",
    "from deeds_pipeline.step5_integration import process_deeds_integration\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "print(f\"✓ nest_asyncio applied for Jupyter compatibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Step 1-2: Json reformatting and ORC extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 15:02:28,076 - step1_json_reformat - INFO - Starting Step 1: JSON Reformat\n",
      "2025-11-17 15:02:28,077 - step1_json_reformat - INFO - Input file: /Users/yifeng/Documents/GitHub/deeds_pipeline/data/deed_reviews_northern_middlesex_20251103_110333.json\n",
      "2025-11-17 15:02:28,077 - step1_json_reformat - INFO - Output file: /Users/yifeng/Documents/GitHub/deeds_pipeline/output/step1_reformatted_by_deed_id.json\n",
      "2025-11-17 15:02:28,078 - step1_json_reformat - INFO - Loading input data...\n",
      "2025-11-17 15:02:28,101 - step1_json_reformat - INFO - Loaded 742 records\n",
      "2025-11-17 15:02:28,101 - step1_json_reformat - INFO - Reformatting data by deed_id...\n",
      "2025-11-17 15:02:28,102 - step1_json_reformat - INFO - Processing 742 deed review records\n",
      "2025-11-17 15:02:28,104 - step1_json_reformat - INFO - Consolidated into 570 unique deed records\n",
      "2025-11-17 15:02:28,104 - step1_json_reformat - INFO - Saving reformatted data...\n",
      "2025-11-17 15:02:28,128 - step1_json_reformat - INFO - Step 1 completed. Output saved to /Users/yifeng/Documents/GitHub/deeds_pipeline/output/step1_reformatted_by_deed_id.json\n",
      "2025-11-17 15:02:28,130 - step1_json_reformat - INFO - Starting Step 1: JSON Reformat\n",
      "2025-11-17 15:02:28,131 - step1_json_reformat - INFO - Input file: /Users/yifeng/Documents/GitHub/deeds_pipeline/data/deed_reviews_northern_middlesex_20251103_110333.json\n",
      "2025-11-17 15:02:28,131 - step1_json_reformat - INFO - Output file: /Users/yifeng/Documents/GitHub/deeds_pipeline/output/step1_reformatted_by_deed_id_test.json\n",
      "2025-11-17 15:02:28,131 - step1_json_reformat - INFO - Loading input data...\n",
      "2025-11-17 15:02:28,151 - step1_json_reformat - INFO - Loaded 742 records\n",
      "2025-11-17 15:02:28,152 - step1_json_reformat - INFO - Reformatting data by deed_id...\n",
      "2025-11-17 15:02:28,152 - step1_json_reformat - INFO - Processing 742 deed review records\n",
      "2025-11-17 15:02:28,154 - step1_json_reformat - INFO - Consolidated into 570 unique deed records\n",
      "2025-11-17 15:02:28,155 - step1_json_reformat - INFO - Saving reformatted data...\n",
      "2025-11-17 15:02:28,178 - step1_json_reformat - INFO - Step 1 completed. Output saved to /Users/yifeng/Documents/GitHub/deeds_pipeline/output/step1_reformatted_by_deed_id_test.json\n"
     ]
    }
   ],
   "source": [
    "from deeds_pipeline.step1_json_reformat import run_step1\n",
    "\n",
    "input_path = Path(\"/Users/yifeng/Documents/GitHub/deeds_pipeline/data/deed_reviews_northern_middlesex_20251103_110333.json\")\n",
    "output_path = Path(\"/Users/yifeng/Documents/GitHub/deeds_pipeline/output/step1_reformatted_by_deed_id_test.json\")\n",
    "# 使用默认配置运行\n",
    "result = run_step1()\n",
    "\n",
    "# 或指定自定义文件路径\n",
    "result = run_step1(\n",
    "    input_file=input_path,\n",
    "    output_file=output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deed_id': '2382', 'reviews': {'26': {'city': None, 'deed_date': '1947-11-13', 'addresses': None, 'is_restrictive_covenant': True, 'exact_language_covenants': None, 'grantors': 'E. Gaston Campbell, Frank J. Rochette, Thomas Rochette', 'grantees': 'William C. Martin, Anna E. Martin', 'additional_locational_information': None, 'exclusion_types': None, 'county': 'Northern Middlesex', 'full_texts': None, 'book_page_urls': ['https://ma-covenants.dataplusfeminism.mit.edu/api/book_pages/1149307/show_page.jpg', 'https://ma-covenants.dataplusfeminism.mit.edu/api/book_pages/1149308/show_page.jpg']}}, 'city': None, 'deed_date': '1947-11-13', 'addresses': None, 'grantors': 'E. Gaston Campbell, Frank J. Rochette, Thomas Rochette', 'grantees': 'William C. Martin, Anna E. Martin', 'additional_locational_information': None, 'exclusion_types': None, 'county': 'Northern Middlesex', 'full_texts': None, 'book_page_urls': ['https://ma-covenants.dataplusfeminism.mit.edu/api/book_pages/1149307/show_page.jpg', 'https://ma-covenants.dataplusfeminism.mit.edu/api/book_pages/1149308/show_page.jpg']}\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"/Users/yifeng/Documents/GitHub/deeds_pipeline/output/step1_reformatted_by_deed_id_test.json\")\n",
    "\n",
    "# read the output file from step1\n",
    "with open(output_path, 'r') as f:\n",
    "    step1_data = json.load(f)\n",
    "\n",
    "# print the first 3 records\n",
    "print(step1_data[list(step1_data.keys())[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deeds_crawl/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/anaconda3/envs/deeds_crawl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-11-18 17:46:31,750 - step2_ocr_extraction - INFO - Using default Google Cloud credentials from gcloud auth\n",
      "2025-11-18 17:46:33,793 - step2_ocr_extraction - INFO - Starting Step 2: OCR and Information Extraction (file mode)\n",
      "2025-11-18 17:46:33,794 - step2_ocr_extraction - INFO - Input file: /Users/yifeng/Documents/GitHub/deeds_pipeline/output/step1_reformatted_by_deed_id.json\n",
      "2025-11-18 17:46:33,794 - step2_ocr_extraction - INFO - Loading Step 1 output...\n",
      "2025-11-18 17:46:33,795 - step2_ocr_extraction - INFO - Loaded 2 deed records\n",
      "2025-11-18 17:46:33,795 - step2_ocr_extraction - INFO - Starting Step 2 processing for 2 deed(s)\n",
      "2025-11-18 17:46:33,795 - step2_ocr_extraction - INFO - Processing deed 1612 (1/2)\n",
      "2025-11-18 17:46:33,796 - step2_ocr_extraction - INFO - Processing 2 images for deed 1612\n",
      "2025-11-18 17:46:33,796 - step2_ocr_extraction - INFO - Deed 1612: Processing image 1/2\n",
      "2025-11-18 17:46:34,274 - step2_ocr_extraction - INFO - \n",
      "2️⃣ Performing OCR using Google Vision API\n",
      "2025-11-18 17:46:35,790 - step2_ocr_extraction - INFO - ✅ OCR completed!\n",
      "2025-11-18 17:46:35,791 - step2_ocr_extraction - INFO - Text length: 2722 characters\n",
      "2025-11-18 17:46:35,792 - step2_ocr_extraction - INFO - ✅ Keywords found: lease\n",
      "2025-11-18 17:46:41,476 - step2_ocr_extraction - INFO - Deed 1612: Processing image 2/2\n",
      "2025-11-18 17:46:41,739 - step2_ocr_extraction - INFO - \n",
      "2️⃣ Performing OCR using Google Vision API\n",
      "2025-11-18 17:46:43,348 - step2_ocr_extraction - INFO - ✅ OCR completed!\n",
      "2025-11-18 17:46:43,349 - step2_ocr_extraction - INFO - Text length: 2528 characters\n",
      "2025-11-18 17:46:43,350 - step2_ocr_extraction - INFO - ✅ Keywords found: race, Caucasian, lease, rent\n",
      "2025-11-18 17:46:49,021 - step2_ocr_extraction - INFO - Processing deed 2168 (2/2)\n",
      "2025-11-18 17:46:49,022 - step2_ocr_extraction - INFO - Processing 2 images for deed 2168\n",
      "2025-11-18 17:46:49,023 - step2_ocr_extraction - INFO - Deed 2168: Processing image 1/2\n",
      "2025-11-18 17:46:49,230 - step2_ocr_extraction - INFO - \n",
      "2️⃣ Performing OCR using Google Vision API\n",
      "2025-11-18 17:46:50,360 - step2_ocr_extraction - INFO - ✅ OCR completed!\n",
      "2025-11-18 17:46:50,361 - step2_ocr_extraction - INFO - Text length: 2702 characters\n",
      "2025-11-18 17:46:50,361 - step2_ocr_extraction - INFO - ✅ Keywords found: covenant\n",
      "2025-11-18 17:47:00,419 - step2_ocr_extraction - INFO - Deed 2168: Processing image 2/2\n",
      "2025-11-18 17:47:00,745 - step2_ocr_extraction - INFO - \n",
      "2️⃣ Performing OCR using Google Vision API\n",
      "2025-11-18 17:47:01,851 - step2_ocr_extraction - INFO - ✅ OCR completed!\n",
      "2025-11-18 17:47:01,852 - step2_ocr_extraction - INFO - Text length: 2528 characters\n",
      "2025-11-18 17:47:01,853 - step2_ocr_extraction - INFO - ✅ Keywords found: race, Caucasian, lease, rent\n",
      "2025-11-18 17:47:06,872 - step2_ocr_extraction - INFO - Step 2 completed for 2 deed(s)\n",
      "2025-11-18 17:47:06,874 - step2_ocr_extraction - INFO - Saving processed data to /Users/yifeng/Documents/GitHub/deeds_pipeline/output/step2_ocr_extracted.json...\n",
      "2025-11-18 17:47:06,875 - step2_ocr_extraction - INFO - Step 2 completed. Output saved to /Users/yifeng/Documents/GitHub/deeds_pipeline/output/step2_ocr_extracted.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 365\n",
      "$365\n",
      "- au-\n",
      "the\n",
      "-emises\n",
      "er\n",
      "Drew\n",
      "lerk\n",
      "P.M.\n",
      "ch of\n",
      "grant\n",
      "■ under\n",
      "cell,\n",
      "are the\n",
      "- pay-\n",
      "in our\n",
      "ereon,\n",
      "\n",
      "Covenant: False\n",
      "Addresses: None\n",
      "Text: 366\n",
      "143\n",
      "Pupkis\n",
      "to\n",
      "Epstein\n",
      "Discharge\n",
      "366\n",
      "į roads, places, drives or avenues, the right to install tel\n",
      "Covenant: False\n",
      "Addresses: None\n"
     ]
    }
   ],
   "source": [
    "# Step 2: OCR Extraction\n",
    "from deeds_pipeline.step2_ocr_extraction import run_step2\n",
    "\n",
    "# 运行 Step 2\n",
    "result = run_step2()\n",
    "\n",
    "# 访问特定契约的 OCR 结果\n",
    "deed_1612 = result[\"1612\"]\n",
    "for ocr_result in deed_1612[\"ocr_results\"]:\n",
    "    print(f\"Text: {ocr_result['ocr_text'][:100]}\")\n",
    "    print(f\"Covenant: {ocr_result['covenant_detection']['covenant_detected']}\")\n",
    "    print(f\"Addresses: {ocr_result['extracted_info']['street_addresses']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Step 3-5: Unified Deed Processing Notebook\n",
    "\n",
    "This notebook implements a stable, function-based pipeline:\n",
    "- **Step 3**: Scrape MassLand Records (using proven massland_scraper.py)\n",
    "- **Step 4**: Geocode streets (with nest_asyncio for Jupyter compatibility)\n",
    "- **Step 5**: Integrate and export data\n",
    "\n",
    "## Key Features\n",
    "- Function call interfaces (no global JSON files required)\n",
    "- Optional JSON checkpointing between steps\n",
    "- Fresh browser per deed (prevents session pollution)\n",
    "- Async-compatible geolocation\n",
    "\n",
    "## Input Format\n",
    "List of deed records:\n",
    "```python\n",
    "[\n",
    "    {\"deed_id\": \"5767\", \"book\": \"57\", \"page\": \"21\", \"county\": \"Middlesex County\", \"town\": \"Dracut\"},\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Utility Functions\n",
    "def load_json(filepath):\n",
    "    \"\"\"Load JSON file\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data, filepath):\n",
    "    \"\"\"Save data to JSON file\"\"\"\n",
    "    Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def extract_book_page_from_urls(urls):\n",
    "    \"\"\"Extract book/page from MassLand URLs\"\"\"\n",
    "    import re\n",
    "    pairs = []\n",
    "    for url in urls:\n",
    "        match = re.search(r'[Bb]ook=(\\d+).*?[Pp]age=(\\d+)', url)\n",
    "        if match:\n",
    "            pairs.append({\"book\": match.group(1), \"page\": match.group(2)})\n",
    "    return pairs\n",
    "\n",
    "print(\"✓ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data: Choose Your Source\n",
    "\n",
    "You can either:\n",
    "1. **Option A**: Load from Step 2 output JSON file\n",
    "2. **Option B**: Manually define test records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3A: OPTION A - Load from Step 2 Output\n\n# Load Step 2 output\nstep2_file = PROJECT_ROOT / \"output\" / \"step2_ocr_extracted.json\"\nstep2_data = load_json(step2_file)\n\n# Convert to list format\ninput_records = []\nfor deed_id, deed_record in step2_data.items():\n    # Extract book/page from OCR results\n    ocr_results = deed_record.get(\"ocr_results\", [])\n    \n    # Collect all book/page pairs from OCR extracted info\n    books = set()\n    pages = set()\n    \n    for ocr_result in ocr_results:\n        extracted_info = ocr_result.get(\"extracted_info\", {})\n        \n        # Get plan_book (can be list or single value)\n        plan_book = extracted_info.get(\"plan_book\")\n        if plan_book:\n            if isinstance(plan_book, list):\n                books.update(plan_book)\n            else:\n                books.add(plan_book)\n        \n        # Get plan_pages (can be list or single value)\n        plan_pages = extracted_info.get(\"plan_pages\")\n        if plan_pages:\n            if isinstance(plan_pages, list):\n                pages.update(plan_pages)\n            else:\n                pages.add(plan_pages)\n    \n    # Create records for each book/page combination\n    if books and pages:\n        for book in books:\n            for page in pages:\n                input_records.append({\n                    \"deed_id\": deed_id,\n                    \"book\": book,\n                    \"page\": page,\n                    \"county\": deed_record.get(\"county\", \"\"),\n                    \"town\": deed_record.get(\"city\", \"\")  # Use 'city' field as town\n                })\n    else:\n        # No book/page found in OCR, skip this deed\n        print(f\"⚠ Warning: Deed {deed_id} has no plan_book/plan_pages in OCR results\")\n\nprint(f\"\\n✓ Loaded {len(step2_data)} deeds from Step 2\")\nprint(f\"✓ Converted to {len(input_records)} book/page records for scraping\")\nprint(f\"\\nSample records:\")\nfor rec in input_records[:3]:\n    print(f\"  - Deed {rec['deed_id']}: Book {rec['book']}, Page {rec['page']}, Town: {rec['town']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using manual input\n",
      "✓ Total records: 2\n",
      "  - Deed 5767: Book 57, Page 21\n",
      "  - Deed 6188: Book 61, Page 88\n"
     ]
    }
   ],
   "source": [
    "# Cell 3B: OPTION B - Manual Input (Alternative)\n",
    "\n",
    "# Uncomment and run this cell instead of 3A for manual testing\n",
    "input_records = [\n",
    "    {\"deed_id\": \"5767\", \"book\": \"57\", \"page\": \"21\", \"county\": \"Middlesex County\", \"town\": \"Dracut\"},\n",
    "    {\"deed_id\": \"6188\", \"book\": \"61\", \"page\": \"88\", \"county\": \"Middlesex County\", \"town\": \"Dracut\"}\n",
    "]\n",
    "\n",
    "print(\"✓ Using manual input\")\n",
    "print(f\"✓ Total records: {len(input_records)}\")\n",
    "for rec in input_records:\n",
    "    print(f\"  - Deed {rec['deed_id']}: Book {rec['book']}, Page {rec['page']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Web Scraping\n",
    "\n",
    "Scrape MassLand Records using the proven massland_scraper.py.\n",
    "- Fresh browser created for each deed (prevents session pollution)\n",
    "- Automatic retry and error handling\n",
    "- Progress logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 15:11:32,048 - step3_scraper - INFO - Starting Step 3 processing for 2 deed(s)\n",
      "2025-11-17 15:11:32,050 - step3_scraper - INFO - [1/2] Processing deed 5767\n",
      "2025-11-17 15:11:32,051 - step3_scraper - INFO - Deed 5767: Scraping 1 book/page combination(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 3: SCRAPING MASSLAND RECORDS\n",
      "================================================================================\n",
      "\n",
      "Input: 2 records\n",
      "Note: Browser will open for each deed (fresh session prevents errors)\n",
      "\n",
      "Browser driver initialized successfully\n",
      "Accessing: https://www.masslandrecords.com/MiddlesexNorth/D/Default.aspx\n",
      "Page loaded successfully\n",
      "Starting search - Book: 57, Page: 21\n",
      "Setting up search criteria...\n",
      "Setting Office to Plans...\n",
      "Current Office value: Recorded Land\n",
      "✓ Selected Office: Plans\n",
      "Setting Search Type to Book Search...\n",
      "Current Search Type value: Plans Name Search\n",
      "✓ Selected Search Type: Plans Book Search\n",
      "✓ Search criteria setup completed\n",
      "Finding Book input box...\n",
      "Entered Book: 57\n",
      "Finding Page input box...\n",
      "Entered Page: 21\n",
      "Finding search button...\n",
      "Clicked search button\n",
      "Waiting for search results...\n",
      "Search results loaded\n",
      "Finding search result table...\n",
      "Found 1 search result(s)\n",
      "First result: File Date=, Book/Page=00:00AM\n",
      "Extracting search result row information...\n",
      "✓ Extracted row info: File Date=10/26/1932, Rec Time=00:00AM, Book/Page=00057/21, Type=PLAN, Town=LOWELL\n",
      "Finding File Date link...\n",
      "✓ Found File Date link by ID\n",
      "Preparing to click File Date link: 10/26/1932\n",
      "✓ Clicked File Date link (via JavaScript)\n",
      "Waiting for metadata area to load...\n",
      "Extracting document details...\n",
      "✓ Extracted document details: 1 row(s)\n",
      "Extracting property information...\n",
      "✓ Extracted property information: 1 row(s)\n",
      "Extracting Grantor/Grantee information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 15:11:53,262 - step3_scraper - INFO - Deed 5767: Completed. Found 1 unique street(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted Grantor/Grantee information: 1 row(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 15:11:53,375 - step3_scraper - INFO - [2/2] Processing deed 6188\n",
      "2025-11-17 15:11:53,376 - step3_scraper - INFO - Deed 6188: Scraping 1 book/page combination(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser closed\n",
      "Browser driver initialized successfully\n",
      "Accessing: https://www.masslandrecords.com/MiddlesexNorth/D/Default.aspx\n",
      "Page loaded successfully\n",
      "Starting search - Book: 61, Page: 88\n",
      "Setting up search criteria...\n",
      "Setting Office to Plans...\n",
      "Current Office value: Recorded Land\n",
      "✓ Selected Office: Plans\n",
      "Setting Search Type to Book Search...\n",
      "Current Search Type value: Plans Name Search\n",
      "✓ Selected Search Type: Plans Book Search\n",
      "✓ Search criteria setup completed\n",
      "Finding Book input box...\n",
      "Entered Book: 61\n",
      "Finding Page input box...\n",
      "Entered Page: 88\n",
      "Finding search button...\n",
      "Clicked search button\n",
      "Waiting for search results...\n",
      "Search results loaded\n",
      "Finding search result table...\n",
      "Found 1 search result(s)\n",
      "First result: File Date=, Book/Page=00:00AM\n",
      "Extracting search result row information...\n",
      "✓ Extracted row info: File Date=12/2/1938, Rec Time=00:00AM, Book/Page=00061/88, Type=PLAN, Town=DRACUT\n",
      "Finding File Date link...\n",
      "✓ Found File Date link by ID\n",
      "Preparing to click File Date link: 12/2/1938\n",
      "✓ Clicked File Date link (via JavaScript)\n",
      "Waiting for metadata area to load...\n",
      "Extracting document details...\n",
      "✓ Extracted document details: 1 row(s)\n",
      "Extracting property information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 15:12:11,148 - step3_scraper - INFO - Deed 6188: Completed. Found 10 unique street(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted property information: 10 row(s)\n",
      "Extracting Grantor/Grantee information...\n",
      "✓ Extracted Grantor/Grantee information: 1 row(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 15:12:11,262 - step3_scraper - INFO - Step 3 completed for 2 deed(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser closed\n",
      "\n",
      "================================================================================\n",
      "STEP 3 COMPLETED\n",
      "================================================================================\n",
      "Checkpoint saved: /Users/yifeng/Documents/GitHub/deeds_pipeline/output/notebook_step3_checkpoint.json\n",
      "Deeds processed: 2/2\n",
      "Total unique streets: 11\n",
      "\n",
      "Sample result:\n",
      "  Deed 5767: 1 streets found\n",
      "  Streets: CHRISTIAN ST\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Run Step 3 - Web Scraping\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 3: SCRAPING MASSLAND RECORDS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nInput: {len(input_records)} records\")\n",
    "print(\"Note: Browser will open for each deed (fresh session prevents errors)\\n\")\n",
    "\n",
    "# Run Step 3 using function interface\n",
    "step3_results = process_deeds_scraping(\n",
    "    deed_records=input_records,\n",
    "    headless=False  # Set to True to hide browser\n",
    ")\n",
    "\n",
    "# Optional: Save checkpoint\n",
    "step3_checkpoint_file = PROJECT_ROOT / \"output\" / \"notebook_step3_checkpoint.json\"\n",
    "save_json({r[\"deed_id\"]: r for r in step3_results}, step3_checkpoint_file)\n",
    "\n",
    "# Statistics\n",
    "total_scraped = sum(1 for r in step3_results if r.get(\"step3_completed\"))\n",
    "total_streets = sum(len(r.get(\"extracted_streets\", [])) for r in step3_results)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"STEP 3 COMPLETED\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Checkpoint saved: {step3_checkpoint_file}\")\n",
    "print(f\"Deeds processed: {total_scraped}/{len(step3_results)}\")\n",
    "print(f\"Total unique streets: {total_streets}\")\n",
    "print(f\"\\nSample result:\")\n",
    "if step3_results:\n",
    "    sample = step3_results[0]\n",
    "    print(f\"  Deed {sample['deed_id']}: {len(sample.get('extracted_streets', []))} streets found\")\n",
    "    print(f\"  Streets: {', '.join(sample.get('extracted_streets', [])[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Geolocation\n",
    "\n",
    "Geocode streets using OpenStreetMap Nominatim API.\n",
    "- Async HTTP requests for better performance\n",
    "- Clustering validation to identify primary location\n",
    "- Works seamlessly in Jupyter (nest_asyncio applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 15:02:48,906 - step4_geolocation - INFO - Event loop detected (likely Jupyter). Using nest_asyncio.\n",
      "2025-11-17 15:02:48,908 - step4_geolocation - INFO - Starting Step 4 processing for 2 deed(s)\n",
      "2025-11-17 15:02:48,908 - step4_geolocation - INFO - StreetClusteringValidator initialized (in-module implementation)\n",
      "2025-11-17 15:02:48,909 - step4_geolocation - INFO - [1/2] Processing deed 5767\n",
      "2025-11-17 15:02:48,910 - step4_geolocation - INFO - Deed 5767: Loaded from cache\n",
      "2025-11-17 15:02:48,910 - step4_geolocation - INFO - [2/2] Processing deed 6188\n",
      "2025-11-17 15:02:48,911 - step4_geolocation - INFO - Deed 6188: Loaded from cache\n",
      "2025-11-17 15:02:48,911 - step4_geolocation - INFO - Step 4 completed for 2 deed(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4: GEOCODING STREETS\n",
      "================================================================================\n",
      "\n",
      "Input: 2 deed records\n",
      "Using OpenStreetMap Nominatim API...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "STEP 4 COMPLETED\n",
      "================================================================================\n",
      "Checkpoint saved: /Users/yifeng/Documents/GitHub/deeds_pipeline/output/notebook_step4_checkpoint.json\n",
      "Deeds geocoded: 2/2\n",
      "Average confidence: 76.4%\n",
      "\n",
      "Sample geolocation:\n",
      "  Deed 5767: (42.6606, -71.2845)\n",
      "    Town: Salisbury Street, Confidence: 65.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Run Step 4 - Geolocation\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 4: GEOCODING STREETS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nInput: {len(step3_results)} deed records\")\n",
    "print(\"Using OpenStreetMap Nominatim API...\\n\")\n",
    "\n",
    "# Run Step 4 using function interface (nest_asyncio handles event loop)\n",
    "step4_results = process_deeds_geolocation(deed_records=step3_results)\n",
    "\n",
    "# Optional: Save checkpoint\n",
    "step4_checkpoint_file = PROJECT_ROOT / \"output\" / \"notebook_step4_checkpoint.json\"\n",
    "save_json({r[\"deed_id\"]: r for r in step4_results}, step4_checkpoint_file)\n",
    "\n",
    "# Statistics\n",
    "geocoded_count = sum(\n",
    "    1 for r in step4_results \n",
    "    if r.get(\"geolocation\") and r[\"geolocation\"].get(\"cluster_center_lat\")\n",
    ")\n",
    "avg_confidence = sum(\n",
    "    r.get(\"geolocation\", {}).get(\"confidence\", 0) \n",
    "    for r in step4_results\n",
    "    if r.get(\"geolocation\")\n",
    ") / max(geocoded_count, 1)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"STEP 4 COMPLETED\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Checkpoint saved: {step4_checkpoint_file}\")\n",
    "print(f\"Deeds geocoded: {geocoded_count}/{len(step4_results)}\")\n",
    "print(f\"Average confidence: {avg_confidence:.1%}\")\n",
    "print(f\"\\nSample geolocation:\")\n",
    "for r in step4_results:\n",
    "    if r.get(\"geolocation\") and r[\"geolocation\"].get(\"cluster_center_lat\"):\n",
    "        geo = r[\"geolocation\"]\n",
    "        print(f\"  Deed {r['deed_id']}: ({geo['cluster_center_lat']:.4f}, {geo['cluster_center_lon']:.4f})\")\n",
    "        print(f\"    Town: {geo.get('primary_town')}, Confidence: {geo.get('confidence', 0):.1%}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Integration\n",
    "\n",
    "Integrate all processing results and export:\n",
    "- Flatten nested data for CSV export\n",
    "- Generate quality report\n",
    "- Export to both JSON and CSV formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 09:35:48,436 - step5_integration - INFO - Starting Step 5 processing for 2 deed(s)\n",
      "2025-11-16 09:35:48,437 - step5_integration - INFO - Flattening deed records...\n",
      "2025-11-16 09:35:48,437 - step5_integration - INFO - Flattened 2 records\n",
      "2025-11-16 09:35:48,438 - step5_integration - INFO - Generating quality report...\n",
      "2025-11-16 09:35:48,438 - step5_integration - INFO - ============================================================\n",
      "2025-11-16 09:35:48,439 - step5_integration - INFO - DATA QUALITY REPORT\n",
      "2025-11-16 09:35:48,439 - step5_integration - INFO - ============================================================\n",
      "2025-11-16 09:35:48,439 - step5_integration - INFO - total_deeds: 2\n",
      "2025-11-16 09:35:48,440 - step5_integration - INFO - step2_ocr_completed: 0\n",
      "2025-11-16 09:35:48,440 - step5_integration - INFO - step2_completion_rate: 0.0%\n",
      "2025-11-16 09:35:48,440 - step5_integration - INFO - step3_scraper_completed: 2\n",
      "2025-11-16 09:35:48,441 - step5_integration - INFO - step3_completion_rate: 100.0%\n",
      "2025-11-16 09:35:48,441 - step5_integration - INFO - step4_geolocation_completed: 2\n",
      "2025-11-16 09:35:48,442 - step5_integration - INFO - step4_completion_rate: 100.0%\n",
      "2025-11-16 09:35:48,442 - step5_integration - INFO - original_covenant_count: 0\n",
      "2025-11-16 09:35:48,442 - step5_integration - INFO - ocr_detected_covenant_count: 0\n",
      "2025-11-16 09:35:48,444 - step5_integration - INFO - geocoded_count: 2\n",
      "2025-11-16 09:35:48,444 - step5_integration - INFO - geocoded_rate: 100.0%\n",
      "2025-11-16 09:35:48,445 - step5_integration - INFO - with_streets_count: 2\n",
      "2025-11-16 09:35:48,445 - step5_integration - INFO - with_streets_rate: 100.0%\n",
      "2025-11-16 09:35:48,445 - step5_integration - INFO - ============================================================\n",
      "2025-11-16 09:35:48,448 - step5_integration - INFO - Step 5 completed for 2 deed(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 5: DATA INTEGRATION AND EXPORT\n",
      "================================================================================\n",
      "\n",
      "Input: 2 deed records\n",
      "\n",
      "================================================================================\n",
      "STEP 5 COMPLETED\n",
      "================================================================================\n",
      "JSON output: /Users/yifeng/Documents/GitHub/deeds_pipeline/output/notebook_final_output.json\n",
      "CSV output: /Users/yifeng/Documents/GitHub/deeds_pipeline/output/notebook_final_output.csv\n",
      "\n",
      "Quality Report:\n",
      "  total_deeds: 2\n",
      "  step2_ocr_completed: 0\n",
      "  step2_completion_rate: 0.0%\n",
      "  step3_scraper_completed: 2\n",
      "  step3_completion_rate: 100.0%\n",
      "  step4_geolocation_completed: 2\n",
      "  step4_completion_rate: 100.0%\n",
      "  original_covenant_count: 0\n",
      "  ocr_detected_covenant_count: 0\n",
      "  geocoded_count: 2\n",
      "  geocoded_rate: 100.0%\n",
      "  with_streets_count: 2\n",
      "  with_streets_rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Run Step 5 - Integration and Export\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 5: DATA INTEGRATION AND EXPORT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nInput: {len(step4_results)} deed records\")\n",
    "\n",
    "# Run Step 5 using function interface\n",
    "final_records, final_df, quality_report = process_deeds_integration(deed_records=step4_results)\n",
    "\n",
    "# Save outputs\n",
    "step5_json_file = PROJECT_ROOT / \"output\" / \"notebook_final_output.json\"\n",
    "step5_csv_file = PROJECT_ROOT / \"output\" / \"notebook_final_output.csv\"\n",
    "\n",
    "# Save JSON (full nested structure)\n",
    "final_json_output = {\n",
    "    \"metadata\": {\n",
    "        \"total_deeds\": len(final_records),\n",
    "        \"quality_report\": quality_report\n",
    "    },\n",
    "    \"deeds\": {r[\"deed_id\"]: r for r in final_records}\n",
    "}\n",
    "save_json(final_json_output, step5_json_file)\n",
    "\n",
    "# Save CSV (flattened structure)\n",
    "final_df.to_csv(step5_csv_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"STEP 5 COMPLETED\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"JSON output: {step5_json_file}\")\n",
    "print(f\"CSV output: {step5_csv_file}\")\n",
    "print(f\"\\nQuality Report:\")\n",
    "for key, value in quality_report.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "View the final processed data and create visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "DataFrame shape: (0, 0)\n",
      "Columns: []\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'geo_latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m display(final_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Geocoding statistics\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m geocoded_count \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeo_latitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotna()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     13\u001b[0m avg_confidence \u001b[38;5;241m=\u001b[39m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeo_confidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGeocoding Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deeds_crawl/lib/python3.10/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deeds_crawl/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'geo_latitude'"
     ]
    }
   ],
   "source": [
    "# Cell 7: View and Analyze Results\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataFrame shape: {final_df.shape}\")\n",
    "print(f\"Columns: {list(final_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(final_df.head())\n",
    "\n",
    "# Geocoding statistics\n",
    "geocoded_count = final_df['geo_latitude'].notna().sum()\n",
    "avg_confidence = final_df['geo_confidence'].mean()\n",
    "\n",
    "print(f\"\\nGeocoding Statistics:\")\n",
    "print(f\"  Total deeds: {len(final_df)}\")\n",
    "print(f\"  Successfully geocoded: {geocoded_count} ({geocoded_count/len(final_df)*100:.1f}%)\")\n",
    "if pd.notna(avg_confidence):\n",
    "    print(f\"  Average confidence: {avg_confidence:.1%}\")\n",
    "\n",
    "# Street extraction statistics\n",
    "with_streets = final_df['scraped_streets'].notna().sum()\n",
    "total_streets = final_df['scraped_street_count'].sum()\n",
    "print(f\"\\nStreet Extraction:\")\n",
    "print(f\"  Deeds with streets: {with_streets} ({with_streets/len(final_df)*100:.1f}%)\")\n",
    "print(f\"  Total streets found: {int(total_streets)}\")\n",
    "print(f\"  Average streets per deed: {total_streets/max(with_streets,1):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create Interactive Map (Optional)\n",
    "\n",
    "try:\n",
    "    import folium\n",
    "    from folium import plugins\n",
    "    \n",
    "    # Create base map\n",
    "    center_lat = final_df['geo_latitude'].mean()\n",
    "    center_lon = final_df['geo_longitude'].mean()\n",
    "    \n",
    "    if pd.notna(center_lat) and pd.notna(center_lon):\n",
    "        m = folium.Map(location=[center_lat, center_lon], zoom_start=11)\n",
    "        \n",
    "        # Add markers for each geocoded deed\n",
    "        for idx, row in final_df.iterrows():\n",
    "            if pd.notna(row['geo_latitude']):\n",
    "                confidence = row.get('geo_confidence', 0)\n",
    "                color = 'green' if confidence > 0.7 else 'orange' if confidence > 0.4 else 'red'\n",
    "                \n",
    "                popup_html = f\"\"\"\n",
    "                <b>Deed {row['deed_id']}</b><br>\n",
    "                Town: {row.get('geo_town', 'N/A')}<br>\n",
    "                Confidence: {confidence:.1%}<br>\n",
    "                Streets: {row.get('scraped_street_count', 0)}<br>\n",
    "                Radius: {row.get('geo_cluster_radius_miles', 0):.2f} mi\n",
    "                \"\"\"\n",
    "                \n",
    "                folium.CircleMarker(\n",
    "                    location=[row['geo_latitude'], row['geo_longitude']],\n",
    "                    radius=8,\n",
    "                    popup=folium.Popup(popup_html, max_width=300),\n",
    "                    color=color,\n",
    "                    fill=True,\n",
    "                    fillColor=color,\n",
    "                    fillOpacity=0.6\n",
    "                ).add_to(m)\n",
    "        \n",
    "        # Add legend\n",
    "        legend_html = '''\n",
    "        <div style=\"position: fixed; \n",
    "                    bottom: 50px; right: 50px; width: 200px; height: 120px; \n",
    "                    background-color: white; z-index:9999; font-size:14px;\n",
    "                    border:2px solid grey; border-radius: 5px; padding: 10px\">\n",
    "        <b>Confidence Legend</b><br>\n",
    "        <i class=\"fa fa-circle\" style=\"color:green\"></i> High (&gt;70%)<br>\n",
    "        <i class=\"fa fa-circle\" style=\"color:orange\"></i> Medium (40-70%)<br>\n",
    "        <i class=\"fa fa-circle\" style=\"color:red\"></i> Low (&lt;40%)\n",
    "        </div>\n",
    "        '''\n",
    "        m.get_root().html.add_child(folium.Element(legend_html))\n",
    "        \n",
    "        # Save map\n",
    "        map_file = PROJECT_ROOT / \"output\" / \"deeds_map.html\"\n",
    "        m.save(str(map_file))\n",
    "        print(f\"✓ Interactive map saved to {map_file}\")\n",
    "        print(f\"  Open in browser to view\")\n",
    "        \n",
    "        # Display in notebook\n",
    "        display(m)\n",
    "    else:\n",
    "        print(\"⚠ No geocoded data available for mapping\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"⚠ folium not installed. Install with: pip install folium\")\n",
    "    print(\"  Skipping map visualization\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Error creating map: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Complete!\n",
    "\n",
    "### Summary\n",
    "- **Step 3**: Web scraping completed with fresh browser instances\n",
    "- **Step 4**: Geocoding completed with async compatibility\n",
    "- **Step 5**: Data integrated and exported\n",
    "\n",
    "### Outputs\n",
    "- `notebook_final_output.json` - Full nested data structure\n",
    "- `notebook_final_output.csv` - Flattened data for analysis\n",
    "- `deeds_map.html` - Interactive map visualization\n",
    "- Checkpoint files at each step for debugging\n",
    "\n",
    "### Next Steps\n",
    "1. Review quality report and identify any failed records\n",
    "2. Analyze geocoding confidence scores\n",
    "3. Use CSV for further analysis or database import"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeds_crawl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}